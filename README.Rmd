---
title: "Survey gaps"
author: "A. Palermino, G. Coro, P. Bove, E.N. Armelloni, G. Scarcella,"
date: "2023"
output: github_document
always_allow_html: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(tidyverse)
library(kableExtra)
library(raster)
Genus_species=read_csv("data/Solea_solea.csv")
missing_hauls=read_csv("data/missing_hauls.csv")
HaulData = read_csv("data/HaulData.csv")
StrataWeight = read_csv("data/StrataWeight.csv")
environmental_variable =raster("data/Environmental_inputs/MaxEnt_2019/CHL_summer_2019.asc")
species = c("Solea_solea")
years = c(2019,2020,2021,2022)

```

## Overview

This repo contains the workflow developed to fill trawl survey haul gaps
based on the paper: "Coro G, Bove P, Armelloni EN, Masnadi F, Scanu M
and Scarcella G (2022) Filling Gaps in Trawl Surveys at Sea through
Spatiotemporal and Environmental Modelling. Front. Mar. Sci. 9:919339.
doi: 10.3389/fmars.2022.919339".

The tool atake into account the spatial mobility of the species through
BIMAC tool (how far can a population go in one year and which is
the mobility of the species?), the historical trends through SSA tool
(what biomass do we expect in the missed hauls given the observation
history?), the environmental aspect through MaxEnt tool (how
inter-annual bio-geo-chemical change affect the species distribution in
the survey year?). Finally through the HBIE tool,the results of the aforementioned tools are weighted and gather to obtain the final biomass index of missing hauls. In the present repo DIVA tool described in Coro et al. (2022) has been replaced by BIMAC.

# Installation

-   Download folder "R", "data" and "java" and store them in a unique
    folder.
    
## Data folders content (provided at installation)

-   Solea_solea.csv; HaulData.csv; StrataWeight.csv: example of input data
-   gebco_30sec_8.asc: world depth data needed for BIMAC
    computation. Do not remove, move or change this file.
-   Subfolder "Envirnmental inputs": contains environmental
    variables of interest for MaxEnt tool. Data provided refers to the Adriatic Sea from 2019 to 2022

## Data preparation guideline

To apply "Survey_gap" to your own case study you need to provide following input files: 

### Genus_species.csv

This file contains the available information regarding your target species abundance and biomass for your study area. The file needs to have the following structure:

```{r, include=T, echo=FALSE}
head(data.frame(Genus_species))

```

where:

  - station: identifier of the survey station. Needs to be consistent over the years.
 
  - lat: Latitude of the station in decimal degree
  
  - lon: Longitude of the station in decimal degree
  
  - year: year of the survey during which the station was carried out
  
  - species: name of the species in the preferred format. Needs to be consistent over the years
  
  - biomindex: biomass index of the station for the interested species
  
  - abunindex: abundance index of the station for the interested species

### missing_hauls.csv

This file contains a list of missing hauls that have to be computed with relative information. The file needs to have the following structure:

```{r, include=T, echo=FALSE}
head(data.frame(missing_hauls))

```

where:

  - station: identifier of the survey station. Needs to be consistent over the years.
  
  - year: year of the survey during which the station was carried out.
  
  - lat: Latitude of the station in decimal degree
  
  - lon: Longitude of the station in decimal degree
  
### HaulData.csv

This file contains the information on the surveyed area. In case of missing haul use the swept area of the previous year:

```{r, include=T, echo=FALSE}
head(data.frame(HaulData))

```

where:

  - Station: identifier of the survey station. Needs to be consistent over the years and includes all the station (missing and not missing station)
  
  - Stratum: identifier of the stratum used for the computation of total biomass index of the area.
  
  - year: year of the survey during which the station was carried out. Need to include the interested year to be filled
  
  - SweptArea: Swept area of the station

### StrataWeight.csv

This file contains information on the surveyed area:

```{r, include=T, echo=FALSE}
head(data.frame(StrataWeight))

```

where:

  - Stratum: identifier of the stratum used for the computation of total biomass index of the area.
  
  - Area: Total area covered by each stratum  
  
  - StratumWeight: Weight of the stratum on the total surveyd area

### Environmental_inputs/variable.asc

Download the raster layer file in asc format for the interested environmental variables:

```{r, include=T, echo=FALSE}
head(environmental_variable)

environmental_variable

```

where:

  - file variable.asc is a matrix containing the values of environmental variable for each cell on the map. 0 values have to be set = -9999 in asc format in order to obtain NA.
  
  - dimensions: identifier of matrix size. nrow, ncol and ncell need to be consistent across all the environmental variables
  
  - resolution: identifier the resolution of the map determining the number of cells 
  
  - extent: extent of the map in longitude and latitude. Need to be consistent across all the environmental variables


## Required data and folder after data preparation

-   Folder "data" containing: "missing_hauls.csv", "Genus_species.csv",
    "HaulData.csv", "StrataWeight.csv",
-   Subfolder "Environmental_inputs" containing the asc files of
    environmental variables to be used for MaxEnt run each year, file
    "gebco_30sec_8.asc": world depth data for BIMAC computations (DO NOT
    EDIT)
-   Folder "R" containing: Code "BIMAC_no_advection.R" for BIMAC
    computations (DO NOT EDIT), code "Workflow_Surveygaps.R", code
    "Workflow_Surveygaps_Solemon.R" with species and year to be filled
    for Solemon survey
-   Folder "java" containing: Code "max_ent_cyb.jar" for MaxEnt
    computations (DO NOT EDIT), code "ssa.jar" for SSA computations (DO
    NOT EDIT), folder "cfg" containing: "operators.xlm" for ssa
    computations (DO NOT EDIT)

# Executing code

Open "Workflow_Surveygaps.R" in RStudio and set working directory to "source file location". In "Workflow_Surveygaps_Solemon.R", data are already selected for the unusable years (2005 and 2006) and hauls ("ms" and "bis")

## Install and load required libraries

library(raster) library (R2jags) library (coda) library(plyr)
library(dplyr) library(digest) library(sqldf)

## Set inputs in "Workflow_Surveygaps.R"

- Line 3: feature selection = FALSE/TRUE:

    ```         
    # feature_selection=T
    ```
    -   if FALSE all the environmental variables stored in the subfolder are used during MaxEnt computation.
    -   if TRUE  only the environmental variables with a certain level of
        importance  (set at the 95% interval of the highest importance level among environmental variables) after the first run are included in MaxEnt computation

- line 4: generate a vector with the name of the species to compute.

```{r, include=T, echo=FALSE}
species

```
    
    -   Terms of the species have to be consistent  with the file names in folder "data":

-   line 5: generate vector with years.

```{r, include=T, echo=FALSE}
years

```

    -   Years have to be consistent with Environmental_inputs subfolders

# Processing
Run the code from "Source" 

README WORK IN PROGRESS

## SSA, BIMAC and MaxEnt computation
In this step several functions are applied to compute temporal, spatial and ecological tools. The results are stored for HBIE computation

 - Inputs are stored in folders named "toolname_input" by species and year
 
 - Output are stored in folders named "toolname_output" by species and year 

## HBIE computation
In this step the temporal (SSA), spatial (BIMAC) and ecological (MaxEnt) results are pulled  together and weighted to give the estimation of mean, low and high biomass index of missing hauls.

 - Inputs are stored in folder named "hbie_input" by species and year 
 
 - Output are stored in folder named "hbie_output" by species and year. The output csv file contain the final biomass index results per station in the column "biomass_est_mean".

## Biomass computation
In this step the total biomass index of the surveyed area is computed from the whole hauls including the filled missing hauls.

 - Inputs are stored in folder named "biom_index_input" by species and year 
 
 - Output are stored in folder named "biom_index_output" by species and year.

README WORK IN PROGRESS
